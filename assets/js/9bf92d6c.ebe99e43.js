"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6846],{11470:(e,n,s)=>{s.d(n,{A:()=>v});var i=s(96540),t=s(34164),l=s(23104),a=s(56347),r=s(205),o=s(57485),c=s(31682),d=s(70679);function u(e){return i.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:s}=e;return(0,i.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:s,default:i}})=>({value:e,label:n,attributes:s,default:i}))}(s);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,s])}function h({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const s=(0,a.W6)(),t=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,o.aZ)(t),(0,i.useCallback)(e=>{if(!t)return;const n=new URLSearchParams(s.location.search);n.set(t,e),s.replace({...s.location,search:n.toString()})},[t,s])]}function x(e){const{defaultValue:n,queryString:s=!1,groupId:t}=e,l=p(e),[a,o]=(0,i.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const s=n.find(e=>e.default)??n[0];if(!s)throw new Error("Unexpected error: 0 tabValues");return s.value}({defaultValue:n,tabValues:l})),[c,u]=m({queryString:s,groupId:t}),[x,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[s,t]=(0,d.Dv)(n);return[s,(0,i.useCallback)(e=>{n&&t.set(e)},[n,t])]}({groupId:t}),b=(()=>{const e=c??x;return h({value:e,tabValues:l})?e:null})();(0,r.A)(()=>{b&&o(b)},[b]);return{selectedValue:a,selectValue:(0,i.useCallback)(e=>{if(!h({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);o(e),u(e),g(e)},[u,g,l]),tabValues:l}}var g=s(92303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var j=s(74848);function f({className:e,block:n,selectedValue:s,selectValue:i,tabValues:a}){const r=[],{blockElementScrollPositionUntilNextRender:o}=(0,l.a_)(),c=e=>{const n=e.currentTarget,t=r.indexOf(n),l=a[t].value;l!==s&&(o(n),i(l))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const s=r.indexOf(e.currentTarget)+1;n=r[s]??r[0];break}case"ArrowLeft":{const s=r.indexOf(e.currentTarget)-1;n=r[s]??r[r.length-1];break}}n?.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,t.A)("tabs",{"tabs--block":n},e),children:a.map(({value:e,label:n,attributes:i})=>(0,j.jsx)("li",{role:"tab",tabIndex:s===e?0:-1,"aria-selected":s===e,ref:e=>{r.push(e)},onKeyDown:d,onClick:c,...i,className:(0,t.A)("tabs__item",b.tabItem,i?.className,{"tabs__item--active":s===e}),children:n??e},e))})}function y({lazy:e,children:n,selectedValue:s}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===s);return e?(0,i.cloneElement)(e,{className:(0,t.A)("margin-top--md",e.props.className)}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==s}))})}function k(e){const n=x(e);return(0,j.jsxs)("div",{className:(0,t.A)("tabs-container",b.tabList),children:[(0,j.jsx)(f,{...n,...e}),(0,j.jsx)(y,{...n,...e})]})}function v(e){const n=(0,g.A)();return(0,j.jsx)(k,{...e,children:u(e.children)},String(n))}},19365:(e,n,s)=>{s.d(n,{A:()=>a});s(96540);var i=s(34164);const t={tabItem:"tabItem_Ymn6"};var l=s(74848);function a({children:e,hidden:n,className:s}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,i.A)(t.tabItem,s),hidden:n,children:e})}},28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>r});var i=s(96540);const t={},l=i.createContext(t);function a(e){const n=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(l.Provider,{value:n},e.children)}},40871:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/gst-single-camera-pipeline-9418b3feb5a3830d46fe8bc7f84042bf.png"},63198:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/copyFileTerminal-6f68b4eebefda3698e800779a70a209e.png"},81133:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/weston-simple-egl-b55a9a199c453851c8dcab4a5fae5ab2.png"},94141:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"Document Home/AI-workflows/run-sample-applications","title":"Run Sample Applications","description":"\u2705 Quick Start Checklist","source":"@site/docs/Document Home/8.AI-workflows/1.run-sample-applications.md","sourceDirName":"Document Home/8.AI-workflows","slug":"/Document Home/AI-workflows/run-sample-applications","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/AI-workflows/run-sample-applications","draft":false,"unlisted":false,"editUrl":"https://github.com/hongyang-rp/rubikpi-ubuntu-user-manual-test-en.github.io/tree/main/docs/Document Home/8.AI-workflows/1.run-sample-applications.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"AI Developer Workflow","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/AI-workflows/"},"next":{"title":"Use Edge Impulse","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/AI-workflows/edge-impulse"}}');var t=s(74848),l=s(28453),a=s(11470),r=s(19365);const o={},c="Run Sample Applications",d={},u=[{value:"\u2705 Quick Start Checklist",id:"-quick-start-checklist",level:3},{value:"Before You Start",id:"before-you-start",level:3},{value:"Run Sample applications",id:"run-sample-applications-1",level:2},{value:"AI Classification Examples in Python",id:"ai-classification-examples-in-python",level:3},{value:"AI Sample Applications",id:"ai-sample-applications",level:3},{value:"Multimedia Sample Applications",id:"multimedia-sample-applications",level:3}];function p(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",input:"input",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"run-sample-applications",children:"Run Sample Applications"})}),"\n",(0,t.jsx)(n.h3,{id:"-quick-start-checklist",children:"\u2705 Quick Start Checklist"}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","Ubuntu 24.04 installed"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","Wi-Fi & SSH set up"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","HDMI display connected"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","Run PPA script for package installs"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","Weston display enabled"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"before-you-start",children:"Before You Start"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Verify Weston Display"}),(0,t.jsx)(n.br,{}),"\n","Check that graphics are working correctly by running this command on the terminal:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"weston-simple-egl\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"weston-test",src:s(81133).A+"",width:"2373",height:"1330"})}),"\n",(0,t.jsxs)(n.admonition,{type:"warning",children:[(0,t.jsx)(n.mdxAdmonitionTitle,{children:(0,t.jsx)(n.strong,{children:"Weston Display Not Working"})}),(0,t.jsxs)(n.p,{children:["If your display doesnt look like the previous image run the following commands in the RubikPi Terminal:",(0,t.jsx)(n.br,{}),"\n",(0,t.jsx)(n.code,{children:"sudo dpkg-reconfigure weston-autostart"})]})]}),"\n",(0,t.jsx)(n.h2,{id:"run-sample-applications-1",children:"Run Sample applications"}),"\n",(0,t.jsxs)(n.p,{children:["This collection of sample applications demonstrates how to build efficient multimedia solutions using ",(0,t.jsx)(n.strong,{children:"LiteRT"}),", ",(0,t.jsx)(n.strong,{children:"OpenCV"}),", and ",(0,t.jsx)(n.strong,{children:"GStreamer"}),"."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"LiteRT"}),": A lightweight runtime framework for modular, high-performance applications."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"OpenCV"}),": A widely-used computer vision library for real-time image and video processing."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"GStreamer"}),": A powerful multimedia framework for building flexible and scalable media pipelines."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"These examples highlight practical approaches to real-time media handling across different integration patterns."}),"\n",(0,t.jsxs)(n.admonition,{type:"tip",children:[(0,t.jsx)(n.mdxAdmonitionTitle,{children:(0,t.jsx)(n.strong,{children:"Pro Tip"})}),(0,t.jsx)(n.p,{children:"Use the fan to avoid overheating"})]}),"\n",(0,t.jsxs)(a.A,{children:[(0,t.jsxs)(r.A,{value:"LiteRT",label:"LiteRT-OpenCV",children:[(0,t.jsx)(n.h3,{id:"ai-classification-examples-in-python",children:"AI Classification Examples in Python"}),(0,t.jsxs)(a.A,{children:[(0,t.jsxs)(r.A,{value:"Terminal",label:"Terminal: Vision Transformer",children:[(0,t.jsxs)(n.p,{children:["Here's how you can run a Vision Transformer model (downloaded from ",(0,t.jsx)(n.a,{href:"https://aihub.qualcomm.com/models/vit",children:"AI Hub"}),") on both the CPU and the NPU using the LiteRT delegates directly on the terminal."]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Create a new venv, and install the LiteRT runtime and Pillow:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"python3 -m venv .venv-litert-demo\nsource .venv-litert-demo/bin/activate\npip3 install ai-edge-litert==1.3.0 Pillow\n"})}),(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsxs)(n.li,{children:["Create ",(0,t.jsx)(n.code,{children:"inference_vit.py"})," and add:"]}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:'import numpy as np\nfrom ai_edge_litert.interpreter import Interpreter, load_delegate\nfrom PIL import Image\nimport os, time, sys\nimport urllib.request\n\ndef curr_ms():\n    return round(time.time() * 1000)\n\nuse_qnn = True if len(sys.argv) >= 2 and sys.argv[1] == \'--use-qnn\' else False\n\n# Path to your quantized TFLite model and test image (will be download automatically)\nMODEL_PATH = "vit-vit-w8a8.tflite"\nIMAGE_PATH = "boa-constrictor.jpg"\nLABELS_PATH = "vit-vit-labels.txt"\n\nif not os.path.exists(MODEL_PATH):\n    print("Downloading model...")\n    model_url = \'https://cdn.edgeimpulse.com/qc-ai-docs/models/vit-vit-w8a8.tflite\'\n    urllib.request.urlretrieve(model_url, MODEL_PATH)\n\nif not os.path.exists(LABELS_PATH):\n    print("Downloading labels...")\n    labels_url = \'https://cdn.edgeimpulse.com/qc-ai-docs/models/vit-vit-labels.txt\'\n    urllib.request.urlretrieve(labels_url, LABELS_PATH)\n\nif not os.path.exists(IMAGE_PATH):\n    print("Downloading image...")\n    image_url = \'https://cdn.edgeimpulse.com/qc-ai-docs/examples/boa-constrictor.jpg\'\n    urllib.request.urlretrieve(image_url, IMAGE_PATH)\n\nwith open(LABELS_PATH, \'r\') as f:\n    labels = [line for line in f.read().splitlines() if line.strip()]\n\nexperimental_delegates = []\nif use_qnn:\n    experimental_delegates = [load_delegate("libQnnTFLiteDelegate.so", options={"backend_type":"htp"})]\n\n# Load TFLite model and allocate tensors\ninterpreter = Interpreter(\n    model_path=MODEL_PATH,\n    experimental_delegates=experimental_delegates\n)\ninterpreter.allocate_tensors()\n\n# Get input and output tensor details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Load and preprocess image\ndef load_image(path, input_shape):\n    # Expected input shape: [1, height, width, channels]\n    _, height, width, channels = input_shape\n\n    img = Image.open(path).convert("RGB").resize((width, height))\n    img_np = np.array(img, dtype=np.uint8)  # quantized models expect uint8\n    img_np = np.expand_dims(img_np, axis=0)\n    return img_np\n\ninput_shape = input_details[0][\'shape\']\ninput_data = load_image(IMAGE_PATH, input_shape)\n\n# Set tensor and run inference\ninterpreter.set_tensor(input_details[0][\'index\'], input_data)\n\n# Run once to warmup\ninterpreter.invoke()\n\n# Then run 10x\nstart = curr_ms()\nfor i in range(0, 10):\n    interpreter.invoke()\nend = curr_ms()\n\n# Get prediction\nq_output = interpreter.get_tensor(output_details[0][\'index\'])\nscale, zero_point = output_details[0][\'quantization\']\nf_output = (q_output.astype(np.float32) - zero_point) * scale\n\n# show top-5 predictions\nscores = f_output[0]\ntop_k = scores.argsort()[-5:][::-1]\nprint("\\nTop-5 predictions:")\nfor i in top_k:\n    print(f"Class {labels[i]}: score={scores[i]}")\n\nprint(\'\')\nprint(f\'Inference took (on average): {(end - start) / 10}ms. per image\')\n'})}),(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsx)(n.li,{children:"Copy file to RubikPi over SSH"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp .\\inference_vit.py ubuntu@<your IP>:/home/ubuntu/\n"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Ssh copy of python to rubikpi",src:s(63198).A+"",width:"998",height:"70"})}),(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsxs)(n.p,{children:["You can retrieve your IP address by executing ",(0,t.jsx)(n.code,{children:"ip addr"})," in the terminal"]})}),(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsx)(n.li,{children:"Run on CPU"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"python3 inference_vit.py\n"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Output of App on Terminal",src:s(95930).A+"",width:"740",height:"318"})}),(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsx)(n.li,{children:"Run on NPU"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"python3 inference_vit.py --use-qnn\n"})}),(0,t.jsx)(n.p,{children:"NPU Inference:"}),(0,t.jsx)(n.p,{children:"INFO: QNN Delegate \u2192 1382/1633 nodes on NPU (27 partitions)\nINFO: XNNPACK Delegate \u2192 CPU fallback"}),(0,t.jsx)(n.p,{children:"\ud83c\udfaf Top-5 Predictions:"}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"\ud83d\udc0d boa constrictor: 7.59"}),"\n",(0,t.jsx)(n.li,{children:"\ud83d\udc0d rock python: 4.82"}),"\n",(0,t.jsx)(n.li,{children:"\ud83d\udc0d night snake: 3.63"}),"\n",(0,t.jsx)(n.li,{children:"\ud83d\udc2d mouse: 2.00"}),"\n",(0,t.jsx)(n.li,{children:"\ud83c\udfa5 lens cap: 1.81"}),"\n"]}),(0,t.jsx)(n.p,{children:"\u26a1\ufe0f Avg Inference: 132.7ms/image"}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Fix logging configuration on the output of Running on the NPU"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add output Picture to replace bottom"]}),"\n"]})]}),(0,t.jsxs)(r.A,{value:"GuiApp",label:"GUI: Image Classification",children:[(0,t.jsx)(n.p,{children:"Pick an image, run it through a model, and get instant predictions. The app lets you switch between CPU and NPU, reprocess images, and experiment\u2014all with a simple GUI using LiteRT."}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Install the essentials"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"    pip install numpy opencv-python tflite-runtime PyGObject\n"})}),(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsx)(n.li,{children:"Get the AI Model + Labels"}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Model: ",(0,t.jsx)(n.a,{href:"https://aihub.qualcomm.com/models/googlenet?domain=Computer+Vision&useCase=Image+Classification",children:"TFLite GoogLeNet-Quantized"})]}),"\n",(0,t.jsxs)(n.li,{children:["Labels:",(0,t.jsx)(n.a,{href:"https://github.com/quic/ai-hub-models/blob/main/qai_hub_models/labels/imagenet_labels.txt",children:"Imagenet labels"})]}),"\n"]}),(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsx)(n.li,{children:"Copy files to RubikPi using SSH"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"    scp googlenet_googlenet-float.tflite ubuntu@<rubikpi ip address>:/home/ubuntu/\n    scp imagenet_labels.txt ubuntu@<rubikpi ip address>:/home/ubuntu/\n"})}),(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsx)(n.li,{children:"Clone aplication directly on RubikPi\nCopy-Paste the Code\nCreate pyGUI-classification.py and drop this in:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"git clone repo \n"})}),(0,t.jsxs)(n.ol,{start:"5",children:["\n",(0,t.jsx)(n.li,{children:"Run the App"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"python3 pyGUI-classification.py\n"})}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: fix repo and clean up app before adding cloning repo location"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add instructions to get AIHUB model"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add images to expected output copying ssh"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: add images of expected output for cloning"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add images to expected output running the app"]}),"\n"]})]})]})]}),(0,t.jsxs)(r.A,{value:"AI",label:"LiteRT-GStreamer",children:[(0,t.jsx)(n.h3,{id:"ai-sample-applications",children:"AI Sample Applications"}),(0,t.jsxs)(a.A,{children:[(0,t.jsxs)(r.A,{value:"classification",label:"Classification",children:[(0,t.jsxs)(n.p,{children:["Here's how you can run a Vision Transformer model (downloaded from ",(0,t.jsx)(n.a,{href:"https://aihub.qualcomm.com/models/vit",children:"AI Hub"}),") on both the CPU and the NPU using the LiteRT delegates directly on the terminal."]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Create a new venv, and install the LiteRT runtime and Pillow:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"python3 -m venv .venv-litert-demo\nsource .venv-litert-demo/bin/activate\npip3 install ai-edge-litert==1.3.0 Pillow\n"})}),(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Create ",(0,t.jsx)(n.code,{children:"inference_vit.py"})," and add:"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Copy file to RubikPi over SSH"}),"\n"]}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp .\\inference_vit.py ubuntu@<your IP>:/home/ubuntu/\n"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Ssh copy of python to rubikpi",src:s(63198).A+"",width:"998",height:"70"})}),(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsxs)(n.p,{children:["You can retrieve your IP address by executing ",(0,t.jsx)(n.code,{children:"ip addr"})," in the terminal"]})}),(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsx)(n.li,{children:"Run on CPU"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"python3 inference_vit.py\n"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Output of App on Terminal",src:s(95930).A+"",width:"740",height:"318"})}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Fix logging configuration on the output of Running on the NPU"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add output Picture to replace bottom"]}),"\n"]})]}),(0,t.jsxs)(r.A,{value:"detection",label:"Object Detection",children:[(0,t.jsx)(n.p,{children:"Pick an image, run it through a model, and get instant predictions. The app lets you switch between CPU and NPU, reprocess images, and experiment\u2014all with a simple GUI using LiteRT."}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Install the essentials"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"    pip install numpy opencv-python tflite-runtime PyGObject\n"})}),(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsx)(n.li,{children:"Get the AI Model + Labels"}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Model: ",(0,t.jsx)(n.a,{href:"https://aihub.qualcomm.com/models/googlenet?domain=Computer+Vision&useCase=Image+Classification",children:"TFLite GoogLeNet-Quantized"})]}),"\n",(0,t.jsxs)(n.li,{children:["Labels:",(0,t.jsx)(n.a,{href:"https://github.com/quic/ai-hub-models/blob/main/qai_hub_models/labels/imagenet_labels.txt",children:"Imagenet labels"})]}),"\n"]}),(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsx)(n.li,{children:"Copy files to RubikPi using SSH"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"    scp googlenet_googlenet-float.tflite ubuntu@<rubikpi ip address>:/home/ubuntu/\n    scp imagenet_labels.txt ubuntu@<rubikpi ip address>:/home/ubuntu/\n"})}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: fix repo and clean up app before adding cloning repo location"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add instructions to get AIHUB model"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add images to expected output copying ssh"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: add images of expected output for cloning"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add images to expected output running the app"]}),"\n"]})]}),(0,t.jsxs)(r.A,{value:"Posedetection",label:"Pose Detection",children:[(0,t.jsx)(n.p,{children:"Pick an image, run it through a model, and get instant predictions. The app lets you switch between CPU and NPU, reprocess images, and experiment\u2014all with a simple GUI using LiteRT."}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Install the essentials"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"    pip install numpy opencv-python tflite-runtime PyGObject\n"})}),(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsx)(n.li,{children:"Get the AI Model + Labels"}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Model: ",(0,t.jsx)(n.a,{href:"https://aihub.qualcomm.com/models/googlenet?domain=Computer+Vision&useCase=Image+Classification",children:"TFLite GoogLeNet-Quantized"})]}),"\n",(0,t.jsxs)(n.li,{children:["Labels:",(0,t.jsx)(n.a,{href:"https://github.com/quic/ai-hub-models/blob/main/qai_hub_models/labels/imagenet_labels.txt",children:"Imagenet labels"})]}),"\n"]}),(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsx)(n.li,{children:"Copy files to RubikPi using SSH"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"    scp googlenet_googlenet-float.tflite ubuntu@<rubikpi ip address>:/home/ubuntu/\n    scp imagenet_labels.txt ubuntu@<rubikpi ip address>:/home/ubuntu/\n"})}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: fix repo and clean up app before adding cloning repo location"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add instructions to get AIHUB model"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add images to expected output copying ssh"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: add images of expected output for cloning"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TODO: Add images to expected output running the app"]}),"\n"]})]})]})]}),(0,t.jsxs)(r.A,{value:"Multimedia",label:"Multimedia-GStreamer",children:[(0,t.jsx)(n.h3,{id:"multimedia-sample-applications",children:"Multimedia Sample Applications"}),(0,t.jsxs)(a.A,{children:[(0,t.jsxs)(r.A,{value:"dashcam",label:"Single camera streaming",children:[(0,t.jsx)(n.p,{children:"Quick summary of application"}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.img,{alt:"App Pipeline",src:s(40871).A+"",width:"1260",height:"753"}),"\n",(0,t.jsx)(n.a,{href:"https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-camera-single-stream-example.html",children:"https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-camera-single-stream-example.html"})]}),(0,t.jsx)(n.p,{children:"Run Camera Example:"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"gst-multi-camera-example -o 0   # View on HDMI\ngst-multi-camera-example -o 1   # Save to /opt/cam1_vid.mp4 & /opt/cam2_vid.mp4\n"})}),(0,t.jsx)(n.p,{children:"Copy Videos to Host:"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"scp ubuntu@<DEVICE_IP>:/opt/cam1_vid.mp4 <destination>\n"})}),(0,t.jsx)(n.p,{children:"Get Help:"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"gst-multi-camera-example --help\n"})}),(0,t.jsxs)(n.p,{children:["\ud83d\uded1 Stop Playback",(0,t.jsx)(n.br,{}),"\n","Ctrl + C"]})]}),(0,t.jsxs)(r.A,{value:"Video Wall",label:"Video wall",children:[(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Start playback:"}),"\n"]}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"gst-concurrent-videoplay-composition -c 4 -i /opt/video1.mp4 -i /opt/video2.mp4 -i /opt/video3.mp4 -i /opt/video4.mp4\n"})}),(0,t.jsx)(n.hr,{}),(0,t.jsx)(n.p,{children:"Prep Your Device"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:'sudo sed -i \'<span class="latex-inline"><span class="katex-error" title="ParseError: KaTeX parse error: Expected group after &#x27;_&#x27; at position 370: \u2026esettings.txt&#x27;\n_\u0332_CODE_BLOCK_1__\u2026" style="color:#cc0000">a deb http://apt.rubikpi.ai ppa main&#x27; /etc/apt/sources.list\nsudo apt update\nsudo apt install -y qcom-ib2c qcom-camera-server qcom-camx\nsudo apt install -y rubikpi3-cameras\nsudo chmod -R 755 /opt\nsudo mkdir -p /var/cache/camera/\nsudo touch /var/cache/camera/camxoverridesettings.txt\nsudo sh -c &#x27;echo enableNCSService=FALSE &gt;&gt; /var/cache/camera/camxoverridesettings.txt&#x27;\n'})}),(0,t.jsx)(n.p,{children:"Add Your Videos (H.264 MP4)"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp &lt;file_name&gt; ubuntu@[DEVICE IP-ADDR]:/opt/\n"})}),(0,t.jsx)(n.p,{children:"Set Up Display"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"export XDG_RUNTIME_DIR=/run/user/</span></span>(id -u ubuntu)/\nexport WAYLAND_DISPLAY=wayland-1\n"})}),(0,t.jsxs)(n.admonition,{type:"note",children:[(0,t.jsxs)(n.p,{children:["If Weston isn\u2019t auto-enabling,here\u2019s the hack:",(0,t.jsx)(n.br,{}),"\n","Open ",(0,t.jsx)(n.strong,{children:"two SSH sessions"})," \u2014 one to wake up Weston, the other to launch your app."]}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1. Fire up Weston (First Shell):"})}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'export GBM_BACKEND=msm && export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && mkdir -p <span class="latex-inline"><span class="katex-error" title="ParseError: KaTeX parse error: Expected &#x27;EOF&#x27;, got &#x27;&amp;&#x27; at position 17: \u2026DG_RUNTIME_DIR &amp;\u0332&amp; weston --cont\u2026" style="color:#cc0000">XDG_RUNTIME_DIR &amp;&amp; weston --continue-without-input --idle-time=0\n'})}),(0,t.jsx)(n.p,{children:"**2. Set the Wayland Display environment(Shell #2)"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"export XDG_RUNTIME_DIR=/run/user/</span></span>(id -u ubuntu)/ && export WAYLAND_DISPLAY=wayland-1\n"})})]}),(0,t.jsx)(n.p,{children:"Play Multiple Videos!"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"gst-concurrent-videoplay-composition -c 4 \\\n-i /opt/<file1>.mp4 \\\n-i /opt/<file2>.mp4 \\\n-i /opt/<file3>.mp4 \\\n-i /opt/<file4>.mp4\n"})}),(0,t.jsxs)(n.p,{children:["\ud83d\uded1 Stop Playback",(0,t.jsx)(n.br,{}),"\n","Ctrl + C"]})]})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},95930:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/outputForTerminalApp-fd4a493663cfd4ea642fbc081bd8a222.png"}}]);