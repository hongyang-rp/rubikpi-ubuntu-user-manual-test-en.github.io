"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7182],{10666:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>t,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Document Home/ai/whisper","title":"Whisper","description":"Whisper is OpenAI\'s general-purpose automatic speech recognition (ASR) model. You can use it for audio transcription, translation, and language identification. You can run Whisper on the NPU of your Dragonwing development board using Qualcomm\'s VoiceAI ASR, or on the CPU using whisper.cpp.","source":"@site/docs/Document Home/8.ai/7.whisper.md","sourceDirName":"Document Home/8.ai","slug":"/Document Home/ai/whisper","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/ai/whisper","draft":false,"unlisted":false,"editUrl":"https://github.com/hongyang-rp/rubikpi-ubuntu-user-manual-test-en.github.io/tree/main/docs/Document Home/8.ai/7.whisper.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Genie","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/ai/genie"},"next":{"title":"IM SDK","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/ai/im_sdk"}}');var r=i(74848),o=i(28453);const a={},l="Whisper",t={},c=[{value:"Running Whisper on the NPU with VoiceAI ASR",id:"running-whisper-on-the-npu-with-voiceai-asr",level:2},{value:"Running Whisper on the CPU with whisper.cpp",id:"running-whisper-on-the-cpu-with-whispercpp",level:2},{value:"Running on the GPU with OpenCL",id:"running-on-the-gpu-with-opencl",level:3}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"whisper",children:"Whisper"})}),"\n",(0,r.jsxs)(n.p,{children:["Whisper is OpenAI's general-purpose automatic speech recognition (ASR) model. You can use it for audio transcription, translation, and language identification. You can run Whisper on the NPU of your Dragonwing development board using Qualcomm's ",(0,r.jsx)(n.a,{href:"https://softwarecenter.qualcomm.com/catalog/item/VoiceAI_ASR",children:"VoiceAI ASR"}),", or on the CPU using ",(0,r.jsx)(n.a,{href:"https://github.com/ggml-org/whisper.cpp",children:"whisper.cpp"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"running-whisper-on-the-npu-with-voiceai-asr",children:"Running Whisper on the NPU with VoiceAI ASR"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Open a terminal on your development board, and set up the base requirements for this example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sudo apt install -y cmake pulseaudio-utils\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Install the ",(0,r.jsx)(n.a,{href:"https://softwarecenter.qualcomm.com/catalog/item/Qualcomm_AI_Runtime_Community?osArch=Any&osType=All&version=2.35.0.250530",children:"AI Runtime SDK - Community Edition"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"wget -qO- https://cdn.edgeimpulse.com/qc-ai-docs/device-setup/install_ai_runtime_sdk_2.35.sh | bash\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Install VoiceAI ASR:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'cd ~/\n\n# https://softwarecenter.qualcomm.com/catalog/item/VoiceAI_ASR, temp mirrored here for devrel purposes, TOOD: remove before launch\nwget https://cdn.edgeimpulse.com/qc-ai-docs/sdk/VoiceAI_ASR_2.1.0.0.zip\nunzip VoiceAI_ASR_2.1.0.0.zip -d voiceai_asr\n\ncd voiceai_asr/2.1.0.0/\n\n# Put the path to VoiceAI ASR in your bash_profile (so it\'s available under VOICEAI_ROOT)\necho "" >> ~/.bash_profile\necho "# Begin VoiceAI ASR" >> ~/.bash_profile\necho "export VOICEAI_ROOT=$PWD" >> ~/.bash_profile\necho "# End VoiceAI ASR" >> ~/.bash_profile\necho "" >> ~/.bash_profile\n\n# Re-load the environment variables\nsource ~/.bash_profile\n\n# Symlink Whisper libraries\ncd $VOICEAI_ROOT/whisper_sdk/libs/npu/rpc_libraries/linux/whisper_all_quantized/\nsudo ln -s $PWD/*.so /usr/lib/\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Build the ",(0,r.jsx)(n.code,{children:"voice-ai-ref"})," example:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd $VOICEAI_ROOT/whisper_sdk/sampleapp/npu_rpc_linux_sample/voice-ai-ref\n\n# overwrite the main.cpp example\nwget -O src/main.cpp https://cdn.edgeimpulse.com/qc-ai-docs/code/voiceai_ref_2.1.0.0_main.cpp\n\n# Symlink Whisper libraries for build\nmkdir -p libs/arm64-v8a/\ncd libs/arm64-v8a/\nln -s $VOICEAI_ROOT/whisper_sdk/libs/npu/rpc_libraries/linux/whisper_all_quantized/*.so .\ncd ../../\n\nmkdir -p build\ncd build\ncmake ..\nmake -j`nproc`\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Download a precompiled Whisper model for the NPU:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/whisper_models/model_qnn_226/\ncd ~/whisper_models/model_qnn_226/\n\nln -s $QAIRT_SRC_ROOT/lib/hexagon-v68/unsigned/libQnnHtpV68Skel.so .\nln -s $VOICEAI_ROOT/whisper_sdk/libs/npu/rpc_libraries/assets/speech_float.eai .\n\n# TODO: Download decoder_model_htp.bin / encoder_model_htp.bin / vocab.bin (ask Jan)\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"You can now transcribe WAV files:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'cd $VOICEAI_ROOT/whisper_sdk/sampleapp/npu_rpc_linux_sample/voice-ai-ref/build\n\n# Download sample file\nwget -O jfk.wav https://raw.githubusercontent.com/ggml-org/whisper.cpp/refs/heads/master/samples/jfk.wav\n\n# Transcribe:\n./voice-ai-ref -f jfk.wav -l en -t transcribe -m ~/whisper-models/model_qnn_226/ | grep -v "No usable logger handle was found" | grep -v "Logs will be sent to"\n\n# ... Expected result:\n# VoiceAIRef final result =  And so my fellow Americans, ask not what your country can do for you, ask what you can do for your country. [language: English]\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Or even do live transcription:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Connect a microphone to your development board."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Find the name of your microphone:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'pactl list short sources\n# 49\talsa_output.platform-sound.stereo-fallback.monitor\tPipeWire\ts24-32le 2ch 48000Hz\tSUSPENDED\n# 76\talsa_input.usb-046d_C922_Pro_Stream_Webcam_C72F6EDF-02.analog-stereo\tPipeWire\ts16le 2ch 32000Hz\tSUSPENDED\n\n# To use the USB webcam, use "alsa_input.usb-046d_C922_Pro_Stream_Webcam_C72F6EDF-02.analog-stereo" as the name\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Run live transcription:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'./voice-ai-ref -r -l en -t transcribe -m ~/whisper-models/model_qnn_226/ -d "alsa_input.usb-046d_C922_Pro_Stream_Webcam_C72F6EDF-02.analog-stereo" | grep -v "No usable logger handle was found" | grep -v "Logs will be sent to"\n\n# VoiceAIRef final result =  Hi, this is to see if I can do live transcription on my Rubik Pi. [language: English]\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["\ud83d\ude80 You now have fully offline transcription of audio on your development board! VoiceAI ASR does not have bindings to higher level languages (like Python), so if you want to use Whisper in your application it's easiest to just spawn the ",(0,r.jsx)(n.code,{children:"voice-ai-ref"})," binary, and read data from stdout."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"running-whisper-on-the-cpu-with-whispercpp",children:"Running Whisper on the CPU with whisper.cpp"}),"\n",(0,r.jsx)(n.p,{children:"Alternatively you can run Whisper on the CPU (with less performance) using whisper.cpp (or any of the other popular Whisper libraries)."}),"\n",(0,r.jsxs)(n.p,{children:["Here's instructions for ",(0,r.jsx)(n.a,{href:"https://github.com/ggml-org/whisper.cpp",children:"whisper.cpp"}),". Open the terminal on your development board, or an ssh session to your development board, and run:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Install build dependencies:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"sudo apt update\nsudo apt install -y libsdl2-dev libsdl2-2.0-0 libasound2-dev\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Build whisper.cpp:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/dev/llm/\ncd ~/dev/llm/\n\ngit clone https://github.com/ggml-org/whisper.cpp.git\ncd whisper.cpp\ngit checkout v1.7.6\n\n# Build (CPU)\ncmake -B build-cpu -DWHISPER_SDL2=ON\ncmake --build build-cpu -j`nproc` --config Release\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Add the whisper.cpp paths to your PATH:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'cd ~/dev/llm/whisper.cpp/build-cpu/bin\n\necho "" >> ~/.bash_profile\necho "# Begin whisper.cpp" >> ~/.bash_profile\necho "export PATH=\\$PATH:$PWD" >> ~/.bash_profile\necho "# End whisper.cpp" >> ~/.bash_profile\necho "" >> ~/.bash_profile\n\n# To use the whisper.cpp files in your current session\nsource ~/.bash_profile\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"You now transcribe some audio using whisper.cpp:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Download model\ncd ~/dev/llm/whisper.cpp\nsh ./models/download-ggml-model.sh tiny.en-q5_1\n\n# Transcribe text\nwhisper-cli -m models/ggml-tiny.en-q5_1.bin -f samples/jfk.wav\n\n# [00:00:00.000 --\x3e 00:00:10.480]\n# and so my fellow Americans ask not what your country can do for you ask what you can do for your country\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"You can also live transcribe audio:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Connect a microphone to your development board."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Find your microphone ID:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"SDL_AUDIODRIVER=alsa whisper-stream -m models/ggml-tiny.en-q5_1.bin\n# init: found 2 capture devices:\n# init:    - Capture device #0: 'qcm6490-rb3-vision-snd-card, '\n# init:    - Capture device #1: 'Yeti Stereo Microphone, USB Audio'\n\n# If you want \"Yeti Stereo Microphone, USB Audio\" then the ID is 1\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Start live transcribing:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"SDL_AUDIODRIVER=alsa whisper-stream -m models/ggml-tiny.en-q5_1.bin -c 1\n\n# main: processing 48000 samples (step = 3.0 sec / len = 10.0 sec / keep = 0.2 sec), 4 threads, lang = en, task = transcribe, timestamps = 0 ...\n# main: n_new_line = 2, no_context = 1\n#\n# [Start speaking]\n# This is a test to see if you can transcribe text live on your Qualcomm device\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"running-on-the-gpu-with-opencl",children:"Running on the GPU with OpenCL"}),"\n",(0,r.jsx)(n.p,{children:"You can build binaries that run on the GPU too via:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["First follow the steps in ",(0,r.jsx)(n.a,{href:"https://qc-ai-test.gitbook.io/qc-ai-test-docs/running-building-ai-models/llama-cpp",children:"llama.cpp"}),' under "Install the OpenCL headers and ICD loader library".']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Build a binary with OpenCL:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd ~/dev/llm/whisper.cpp\n\ncmake -B build-gpu -DGGML_OPENCL=ON  -DWHISPER_SDL2=ON\ncmake --build build-gpu -j`nproc` --config Release\n\n# Find the binary in:\n#     build-gpu/bin/whisper-cli\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"But this does not run faster than on CPU, at least on QCS6490 (even with Q4_0 quantized weights)."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>l});var s=i(96540);const r={},o=s.createContext(r);function a(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);