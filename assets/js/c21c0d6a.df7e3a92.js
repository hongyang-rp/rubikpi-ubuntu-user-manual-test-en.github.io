"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[679],{717:(e,n,s)=>{s.d(n,{A:()=>l});const l=s.p+"assets/images/image-15-e1706e3d6a9e8607505fbaa5b5512925.png"},1470:(e,n,s)=>{s.d(n,{A:()=>w});var l=s(6540),t=s(4164),i=s(3104),a=s(6347),r=s(205),o=s(7485),c=s(1682),d=s(679);function h(e){return l.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:s}=e;return(0,l.useMemo)(()=>{const e=n??function(e){return h(e).map(({props:{value:e,label:n,attributes:s,default:l}})=>({value:e,label:n,attributes:s,default:l}))}(s);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,s])}function u({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const s=(0,a.W6)(),t=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,o.aZ)(t),(0,l.useCallback)(e=>{if(!t)return;const n=new URLSearchParams(s.location.search);n.set(t,e),s.replace({...s.location,search:n.toString()})},[t,s])]}function x(e){const{defaultValue:n,queryString:s=!1,groupId:t}=e,i=p(e),[a,o]=(0,l.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const s=n.find(e=>e.default)??n[0];if(!s)throw new Error("Unexpected error: 0 tabValues");return s.value}({defaultValue:n,tabValues:i})),[c,h]=m({queryString:s,groupId:t}),[x,j]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[s,t]=(0,d.Dv)(n);return[s,(0,l.useCallback)(e=>{n&&t.set(e)},[n,t])]}({groupId:t}),g=(()=>{const e=c??x;return u({value:e,tabValues:i})?e:null})();(0,r.A)(()=>{g&&o(g)},[g]);return{selectedValue:a,selectValue:(0,l.useCallback)(e=>{if(!u({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);o(e),h(e),j(e)},[h,j,i]),tabValues:i}}var j=s(2303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var f=s(4848);function b({className:e,block:n,selectedValue:s,selectValue:l,tabValues:a}){const r=[],{blockElementScrollPositionUntilNextRender:o}=(0,i.a_)(),c=e=>{const n=e.currentTarget,t=r.indexOf(n),i=a[t].value;i!==s&&(o(n),l(i))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const s=r.indexOf(e.currentTarget)+1;n=r[s]??r[0];break}case"ArrowLeft":{const s=r.indexOf(e.currentTarget)-1;n=r[s]??r[r.length-1];break}}n?.focus()};return(0,f.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,t.A)("tabs",{"tabs--block":n},e),children:a.map(({value:e,label:n,attributes:l})=>(0,f.jsx)("li",{role:"tab",tabIndex:s===e?0:-1,"aria-selected":s===e,ref:e=>{r.push(e)},onKeyDown:d,onClick:c,...l,className:(0,t.A)("tabs__item",g.tabItem,l?.className,{"tabs__item--active":s===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:s}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===s);return e?(0,l.cloneElement)(e,{className:(0,t.A)("margin-top--md",e.props.className)}):null}return(0,f.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,l.cloneElement)(e,{key:n,hidden:e.props.value!==s}))})}function y(e){const n=x(e);return(0,f.jsxs)("div",{className:(0,t.A)("tabs-container",g.tabList),children:[(0,f.jsx)(b,{...n,...e}),(0,f.jsx)(v,{...n,...e})]})}function w(e){const n=(0,j.A)();return(0,f.jsx)(y,{...e,children:h(e.children)},String(n))}},2175:(e,n,s)=>{s.d(n,{A:()=>l});const l=s.p+"assets/images/image-17-82b0632558689ab4f2f897791cae3579.png"},2553:(e,n,s)=>{s.d(n,{A:()=>l});const l=s.p+"assets/images/image-11-05e0063c30f4780270fe5e399a1250f3.png"},2999:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>h});const l=JSON.parse('{"id":"Document Home/Quick Start/Run sample applications","title":"Run sample applications","description":"RUBIK Pi 3 Ubuntu 24.04 includes various sample applications.","source":"@site/docs/Document Home/1. Quick Start/3.Run sample applications.md","sourceDirName":"Document Home/1. Quick Start","slug":"/Document Home/Quick Start/Run sample applications","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/Quick Start/Run sample applications","draft":false,"unlisted":false,"editUrl":"https://github.com/hongyang-rp/rubikpi-ubuntu-user-manual-test-en.github.io/tree/main/docs/Document Home/1. Quick Start/3.Run sample applications.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Set up your device","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/Quick Start/Set up your device"},"next":{"title":"Update software","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/Document Home/Quick Start/Update software"}}');var t=s(4848),i=s(8453),a=s(1470),r=s(9365);const o={},c="Run sample applications",d={},h=[{value:"Prerequisites for running sample applications",id:"prerequisites-for-running-sample-applications",level:2},{value:"Run sample applications using RUBIK Pi Tools",id:"run-sample-applications-using-rubik-pi-tools",level:2},{value:"Run multimedia sample applications",id:"run-multimedia-sample-applications",level:2},{value:"Run AI sample applications",id:"run-ai-sample-applications",level:2},{value:"More applications",id:"more-applications",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)("a",{id:"runsample"}),"\n",(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"run-sample-applications",children:"Run sample applications"})}),"\n",(0,t.jsx)(n.p,{children:"RUBIK Pi 3 Ubuntu 24.04 includes various sample applications."}),"\n",(0,t.jsx)(n.p,{children:"You can run these applications using one of the following methods:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Use the RUBIK Pi Tools (a GUI-based application) to run the sample applications."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(6304).A+"",width:"1117",height:"622"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Manually run the sample applications:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"#run-multimedia-sample-applications",children:"Run multimedia sample applications"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"#run-ai-sample-applications",children:"Run AI sample applications"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To run the multimedia and AI applications, set up the Wi-Fi connection and establish an SSH connection."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To view the display output, connect an HDMI display to the HDMI port of RUBIK Pi 3, refer to [Connect an HDMI display](./2.setup-device.md#connect an hdmi display)."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To enable audio, please refer to Audio."}),"\n"]}),"\n"]})}),"\n",(0,t.jsx)("a",{id:"prererunsample"}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites-for-running-sample-applications",children:"Prerequisites for running sample applications"}),"\n",(0,t.jsx)(n.p,{children:"Before running the sample applications, enable the Weston display to activate the full functionality of the camera and AI capabilities. The steps are as follows:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Add the Qualcomm PPA to the Ubuntu sources."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Add the Qualcomm Public Personal Package Archive (PPA) to the software sources of your RUBIK Pi 3 Ubuntu."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo add-apt-repository ppa:ubuntu-qcom-iot/qcom-noble-ppa\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(2553).A+"",width:"1229",height:"320"})}),"\n",(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsx)(n.li,{children:"Update and install the dependencies."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo apt update && sudo apt upgrade\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install Weston and test the basic display functionality."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Install Weston and the related software packages."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo apt install weston-autostart gstreamer1.0-qcom-sample-apps gstreamer1.0-tools qcom-fastcv-binaries-dev qcom-video-firmware weston-autostart libgbm-msm1 qcom-adreno1\nsudo reboot\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsx)(n.li,{children:"Set up the display environment as the root user."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo -i\nexport XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Connect the HDMI display and wait a moment. The Weston desktop will be displayed on the screen."}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["If the Weston desktop is not displayed properly, try entering the ",(0,t.jsx)(n.code,{children:"sudo dpkg-reconfigure weston-autostart"})," command in the RUBIK Pi terminal."]})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To test the graphics, run the sample application. The following example runs the Weston-simple-egl:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"weston-simple-egl\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(6466).A+"",width:"1085",height:"630"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"run-sample-applications-using-rubik-pi-tools",children:"Run sample applications using RUBIK Pi Tools"}),"\n",(0,t.jsx)(n.p,{children:"RUBIK Pi Tools is a GUI-based application that provides an easy way to experience the AI and multimedia features of the RUBIK Pi development kit. With just a single click, you can start using this application without the need to set up a host system. It also has the capability to connect directly to Wi-Fi."}),"\n",(0,t.jsx)("a",{id:"runmediaapp"}),"\n",(0,t.jsx)(n.h2,{id:"run-multimedia-sample-applications",children:"Run multimedia sample applications"}),"\n",(0,t.jsx)(n.p,{children:"The multimedia sample applications show various use cases for the camera, display, and video streaming capabilities of RUBIK Pi."}),"\n",(0,t.jsxs)(a.A,{children:[(0,t.jsxs)(r.A,{value:"dashcam",label:"Multi-camera streaming or encoding (dashcam)",children:[(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"gst-multi-camera-example"})," command-line application demonstrates simultaneous streaming from two camera sensors on RUBIK Pi 3. This application composites the video streams side by side and displays them on a monitor, or encodes the video streams and saves them to a file."]}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(7595).A+"",width:"792",height:"524"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example"})}),(0,t.jsxs)(n.p,{children:["Before running the application, make sure the ",(0,t.jsx)(n.a,{href:"#prerequisites-for-running-sample-applications",children:"Weston display is enabled"}),". To launch the application, run the following use case from the SSH terminal:"]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install the camera-related software."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Add the RUBIK Pi PPA to Ubuntu sources and update the package list:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo sed -i '$a deb http://apt.rubikpi.ai ppa main' /etc/apt/sources.list\nsudo apt update\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install the camera software."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo apt install -y qcom-ib2c qcom-camera-server qcom-camx\nsudo apt install -y rubikpi3-cameras\nsudo chmod -R 777 /opt\nsudo mkdir -p /var/cache/camera/\nsudo touch /var/cache/camera/camxoverridesettings.txt\necho  enableNCSService=FALSE >> /var/cache/camera/camxoverridesettings.txt\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To view the sample application on the HDMI display, run the following export command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && export WAYLAND_DISPLAY=wayland-1\n"})}),"\n",(0,t.jsxs)(n.admonition,{type:"note",children:[(0,t.jsx)(n.p,{children:"If Weston is not automatically enabled, start two secure shell instances - one to enable Weston, and another to run the application."}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To enable Weston, run the following command in the first shell:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"export GBM_BACKEND=msm && export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && mkdir -p $XDG_RUNTIME_DIR && weston --continue-without-input --idle-time=0"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To set up the Wayland Display environment, run the following command in the second shell:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && export WAYLAND_DISPLAY=wayland-1"})}),"\n"]}),"\n"]})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["To view the ",(0,t.jsx)(n.code,{children:"waylandsink"})," output, run the following command:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"gst-multi-camera-example -o 0\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To store the encoder output, follow these steps:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Run the following command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"gst-multi-camera-example -o 1\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The device will store the encoded files in ",(0,t.jsx)(n.code,{children:"/opt/cam1_vid.mp4"})," and ",(0,t.jsx)(n.code,{children:"/opt/cam2_vid.mp4"}),", for camera 1 and camera 2 respectively."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Run the following command to extract the files from the host:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp ubuntu@<IP address of target device>:/opt/cam1_vid.mp4 <destination directory>\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To play the encoder output, use any media player that supports MP4 files."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["To stop the use case, press ",(0,t.jsx)(n.strong,{children:"Ctrl"})," + ",(0,t.jsx)(n.strong,{children:"C"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To display the available help options, run the following command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"gst-multi-camera-example --help\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"GST_DEBUG"})," environment variable controls the GStreamer debug output. Set the desired level to allow logging. For example, to log all warnings, run the following command:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"export GST_DEBUG=2\n"})}),"\n"]}),"\n"]})]}),(0,t.jsxs)(r.A,{value:"wall",label:"Multichannel video decode and compose (Video wall)",children:[(0,t.jsx)(n.p,{children:"The gst-concurrent-videoplay-composition command-line application allows concurrent video decoding and playback for AVC-coded videos and composes them on a display for video wall applications. The application requires at least one input video file, which should be an MP4 file with the AVC codec."}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(7684).A+"",width:"1025",height:"479"})}),(0,t.jsxs)(n.p,{children:["Before running the application, make sure the ",(0,t.jsx)(n.a,{href:"#prerequisites-for-running-sample-applications",children:"Weston display is enabled"}),". To launch the application, run the following use case from the SSH terminal:"]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install the camera-related software."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Add the RUBIK Pi PPA to Ubuntu sources and update the package list:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo sed -i '$a deb http://apt.rubikpi.ai ppa main' /etc/apt/sources.list\nsudo apt update\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install the camera software."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo apt install -y qcom-ib2c qcom-camera-server qcom-camx\nsudo apt install -y rubikpi3-cameras\nsudo chmod -R 777 /opt\nsudo mkdir -p /var/cache/camera/\nsudo touch /var/cache/camera/camxoverridesettings.txt\necho  enableNCSService=FALSE >> /var/cache/camera/camxoverridesettings.txt\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["To transfer prerecorded or test videos that are in the AVC-encoded MP4 (H.264) format (with the filename as ",(0,t.jsx)(n.code,{children:"<file_name>"}),") to your device, run the following command on the host computer:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp <file_name> ubuntu@[DEVICE IP-ADDR]:/opt/\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To view the sample application on the HDMI display, run the following export command from the SSH terminal:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && export WAYLAND_DISPLAY=wayland-1\n"})}),"\n"]}),"\n"]}),(0,t.jsxs)(n.admonition,{type:"note",children:[(0,t.jsx)(n.p,{children:"If Weston is not automatically enabled, start two secure shell instances - one to enable Weston, and another to run the application."}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To enable Weston, run the following command in the first shell:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"export GBM_BACKEND=msm && export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && mkdir -p $XDG_RUNTIME_DIR && weston --continue-without-input --idle-time=0"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To set up the Wayland Display environment, run the following command in the second shell:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && export WAYLAND_DISPLAY=wayland-1"})}),"\n"]}),"\n"]})]}),(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsx)(n.li,{children:"To start concurrent playback for four channels, run the following command:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"gst-concurrent-videoplay-composition -c 4 -i /opt/<file_name1>.mp4 -i /opt/<file_name2>.mp4 -i /opt/<file_name3>.mp4 -i /opt/<file_name4>.mp4\n"})}),(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"-c"}),": specifies the number of streams to be decoded for composition can be either 2, 4, or 8."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"-i"}),": specifies the absolute path to the input video file."]}),"\n"]}),"\n"]})}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["To stop the use case, press ",(0,t.jsx)(n.strong,{children:"Ctrl"})," + ",(0,t.jsx)(n.strong,{children:"C"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To display the available help options, run the following command:"}),"\n"]}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"gst-concurrent-videoplay-composition --help\n"})}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.code,{children:"GST_DEBUG"})," environment variable controls the GStreamer debug output. Set the required level to allow logging. For example, to log all warnings, run the following command:"]}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"export GST_DEBUG=2\n"})})]})]}),"\n",(0,t.jsx)("a",{id:"runsampleapp"}),"\n",(0,t.jsx)(n.h2,{id:"run-ai-sample-applications",children:"Run AI sample applications"}),"\n",(0,t.jsxs)(n.p,{children:["AI sample applications show use cases for object detection and parallel inferencing on input streams from a camera, video file, or Real-Time Streaming Protocol (RTSP) stream on the RUBIK Pi 3 device. To run these sample applications, you must obtain AI models from ",(0,t.jsx)(n.a,{href:"https://aihub.qualcomm.com/iot/models",children:"Qualcomm\xae AI Hub"})," and labels from GitHub. The procedure involves downloading the models and labels, transferring them to RUBIK Pi 3, and running the sample applications."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(717).A+"",width:"1413",height:"179"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Prerequisites"})}),"\n",(0,t.jsx)(n.p,{children:"The device requires models and label files to run the AI sample applications."}),"\n",(0,t.jsx)("a",{id:"proced"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Procedure"})}),"\n",(0,t.jsxs)(n.p,{children:["Before running the application, make sure the ",(0,t.jsx)(n.a,{href:"#prerequisites-for-running-sample-applications",children:"Weston display is enabled"}),". To launch the application, run the following use case from the SSH terminal:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install the camera-related software."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Add the RUBIK Pi PPA to Ubuntu sources and update the package list:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo sed -i '$a deb http://apt.rubikpi.ai ppa main' /etc/apt/sources.list\nsudo apt update\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install the camera software."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sudo apt install -y qcom-ib2c qcom-camera-server qcom-camx\nsudo apt install -y rubikpi3-cameras\nsudo chmod -R 777 /opt\nsudo mkdir -p /var/cache/camera/\nsudo touch /var/cache/camera/camxoverridesettings.txt\necho  enableNCSService=FALSE >> /var/cache/camera/camxoverridesettings.txt\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"You need the following models for the AI sample applications:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Sample Application"}),(0,t.jsx)(n.th,{children:"Required Model"}),(0,t.jsx)(n.th,{children:"Required label file"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"AI object detection"}),(0,t.jsx)(n.td,{children:"yolov8_det_quantized.tflite"}),(0,t.jsx)(n.td,{children:"yolonas.labels"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Parallel AI inference"}),(0,t.jsx)(n.td,{children:"yolov8_det_quantized.tflite"}),(0,t.jsx)(n.td,{children:"yolov8.labels"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Parallel AI inference"}),(0,t.jsx)(n.td,{children:"inception_v3_quantized.tflite"}),(0,t.jsx)(n.td,{children:"classification.labels"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Parallel AI inference"}),(0,t.jsx)(n.td,{children:"hrnet_pose_quantized.tflite"}),(0,t.jsx)(n.td,{children:"hrnet_pose.labels"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Parallel AI inference"}),(0,t.jsx)(n.td,{children:"deeplabv3_plus_mobilenet_quantized.tflite"}),(0,t.jsx)(n.td,{children:"deeplabv3_resnet50.labels"})]})]})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Download and run the automated script to get the model and label files on the device:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"curl -L -O https://raw.githubusercontent.com/quic/sample-apps-for-qualcomm-linux/refs/heads/main/download_artifacts.sh\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"chmod +x download_artifacts.sh\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"./download_artifacts.sh -v GA1.4-rel -c QCS6490\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsx)(n.p,{children:"The YOLOv8 models are not part of the script. You need to export these models using the Qualcomm AI Hub APIs."})}),"\n",(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Export YOLOv8 from Qualcomm AI Hub."}),"\n",(0,t.jsx)(n.p,{children:"Follow these validated instructions to export models on your host computer using Ubuntu 22.04. You can also run these instructions on Windows through Windows Subsystem for Linux (WSL) or set up an Ubuntu 22.04 virtual machine on macOS. For more details, see Virtual Machine Setup Guide."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Obtain the shell script for exporting the models:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"wget https://raw.githubusercontent.com/quic/sample-apps-for-qualcomm-linux/refs/heads/main/scripts/export_model.sh\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Update the script permissions to make it executable:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"chmod +x export_model.sh\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Run the export script with your Qualcomm AI Hub API token as the value for the --api-token argument:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"./export_model.sh --api-token=<Your AI Hub API Token>\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["You can find your Qualcomm AI Hub API token in your ",(0,t.jsx)(n.a,{href:"https://app.aihub.qualcomm.com/account/",children:"account settings"}),"."]})}),"\n",(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The script downloads the models to the ",(0,t.jsx)(n.code,{children:"build"})," directory. Copy these models to the ",(0,t.jsx)(n.em,{children:"/etc/models/"})," directory of your device using the following commands:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp <working directory>/build/yolonas_quantized/yolonas_quantized.tflite ubuntu@<IP address of target device>:/etc/models/\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp <working directory>/build/yolov8_det_quantized/yolov8_det_quantized.tflite ubuntu@<IP address of target device>:/etc/models/\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Update the ",(0,t.jsx)(n.code,{children:"q_offset"})," and ",(0,t.jsx)(n.code,{children:"q_scale"})," constants of the quantized LiteRT model in the JSON file. For instructions, refer to Get the model constants."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Use the following command to push the downloaded model files to the device:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp <model filename> ubuntu@<IP addr of the target device>:/etc/models\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"unzip rubikpi3_ai_sample_apps_models_labels.zip\ncd rubikpi3_ai_sample_apps_models_labels\nscp inception_v3_quantized.tflite ubuntu@<IP addr of the target device>:/etc/models/\nscp yolonas.labels ubuntu@<IP addr of the target device>:/etc/labels/\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"7",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Create a directory for test videos using the following commands:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"ssh ubuntu@<ip-addr of the target device>\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"mount -o remount, rw /usr\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"mkdir /etc/media/\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"From the host computer, push the test video files to the device:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp <filename>.mp4 ubuntu@<IP address of target device>:/etc/media/\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(a.A,{children:[(0,t.jsxs)(r.A,{value:"AIobject",label:"AI object detection",children:[(0,t.jsx)(n.p,{children:"The gst-ai-object-detection sample application shows the hardware capability to detect objects on input streams from a camera, video file, or RTSP stream. The pipeline receives the input stream, preprocesses it, runs inferences on AI hardware, and displays the results on the screen."}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(9510).A+"",width:"1025",height:"479"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example"})}),(0,t.jsxs)(n.p,{children:["You must push the model and label files to the device to run the sample application. For details, see ",(0,t.jsx)(n.a,{href:"#proced",children:"Procedure"}),"."]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Begin a new SSH session and start the HDMI display monitor if you haven't already:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:"ssh ubuntu@<ip-addr of the target device>\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To view the sample application on the HDMI display, run the following export command from the SSH terminal:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && export WAYLAND_ DISPLAY=wayland-1\n"})}),"\n"]}),"\n"]}),(0,t.jsxs)(n.admonition,{type:"note",children:[(0,t.jsx)(n.p,{children:"If Weston is not automatically enabled, start two secure shell instances - one to enable Weston, and another to run the application."}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To enable Weston, run the following command in the first shell:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"export GBM_BACKEND=msm && export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && mkdir -p $XDG_RUNTIME_DIR && weston --continue-without-input --idle-time=0"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To set up the Wayland Display environment, run the following command in the second shell:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && export WAYLAND_DISPLAY=wayland-1"})}),"\n"]}),"\n"]})]}),(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsxs)(n.li,{children:["Modify the ",(0,t.jsx)(n.code,{children:"/etc/configs/config_detection.json"})," file on your device."]}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n   "file-path": "/etc/media/video.mp4",\n   "ml-framework": "tflite",\n   "yolo-model-type": "yolov8",\n   "model": "/etc/models/yolov8_det_quantized.tflite",\n   "labels": "/etc/labels/yolonas.labels",\n   "constants": "YOLOv8,q-offsets=<21.0, 0.0, 0.0>,q-scales=<3.0546178817749023, 0.003793874057009816, 1.0>;",\n   "threshold": 40,\n   "runtime": "dsp"\n}\n'})}),(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Field"}),(0,t.jsx)(n.th,{children:"Values/description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"ml-framework"})}),(0,t.jsx)(n.td,{})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"snpe"}),(0,t.jsx)(n.td,{children:"Uses the Qualcomm\xae Neural Processing SDK models"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"tflite"}),(0,t.jsx)(n.td,{children:"Uses the LiteRT models"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"qnn"}),(0,t.jsx)(n.td,{children:"Uses the Qualcomm\xae AI Engine direct models"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"yolo-model-type"})}),(0,t.jsx)(n.td,{})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"yolov5 yolov8 yolonas"}),(0,t.jsx)(n.td,{children:"Runs the YOLOv5, YOLOv8, and YOLO-NAS models, respectively. See Sample model and label files."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"runtime"})}),(0,t.jsx)(n.td,{})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"cpu"}),(0,t.jsx)(n.td,{children:"Runs on the CPU"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"gpu"}),(0,t.jsx)(n.td,{children:"Runs on the GPU"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"dsp"}),(0,t.jsx)(n.td,{children:"Runs on the digital signal processor (DSP)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Input source"})}),(0,t.jsx)(n.td,{})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"camera"}),(0,t.jsxs)(n.td,{children:[(0,t.jsx)("p",{children:"0 \u2013 Primary camera"}),(0,t.jsx)("p",{children:"1 \u2013 Secondary camera"})]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"file-path"}),(0,t.jsx)(n.td,{children:"Directory path to the video file"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"rtsp-ip-port"}),(0,t.jsxs)(n.td,{children:["Address of the RTSP stream in ",(0,t.jsx)(n.code,{children:"rtsp://<ip>:/<stream>"})," format"]})]})]})]}),(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To start the application, run the following command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"gst-ai-object-detection\n"})}),"\n"]}),"\n"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["To stop the use case, press ",(0,t.jsx)(n.strong,{children:"Ctrl"})," + ",(0,t.jsx)(n.strong,{children:"C"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To display the available help options, run the following command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"gst-ai-object-detection -h\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"GST_DEBUG"})," environment variable controls the GStreamer debug output. Set the required level to allow logging. For example, to log all warnings, run the following command:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c++",children:"export GST_DEBUG=2\n"})}),"\n"]}),"\n"]})]}),(0,t.jsxs)(r.A,{value:"parallelAI",label:"Parallel AI inference",children:[(0,t.jsx)(n.p,{children:"The gst-ai-parallel-inference command-line application shows the hardware capability to perform four parallel AI inferences on input streams from a camera, video file, or RTSP stream. The pipeline detects objects, classifies objects, detects poses, and segments images on the input stream. The screen displays the results side-by-side."}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(2175).A+"",width:"1025",height:"479"})}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example"})}),(0,t.jsxs)(n.p,{children:["You must push the model and label files to the device to run the sample application. For details, see ",(0,t.jsx)(n.a,{href:"#proced",children:"Procedure"}),"."]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Begin a new SSH session and start the HDMI display monitor if you haven't already:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:"ssh ubuntu@<ip-addr of the target device>\n"})}),(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsx)(n.li,{children:"To view the sample application on the HDMI display, run the following export command from the SSH terminal:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && export WAYLAND_ DISPLAY=wayland-1\n"})}),(0,t.jsxs)(n.admonition,{type:"note",children:[(0,t.jsx)(n.p,{children:"If Weston is not automatically enabled, start two secure shell instances - one to enable Weston, and another to run the application."}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To enable Weston, run the following command in the first shell:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"export GBM_BACKEND=msm && export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && mkdir -p $XDG_RUNTIME_DIR && weston --continue-without-input --idle-time=0"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To set up the Wayland Display environment, run the following command in the second shell:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"export XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)/ && export WAYLAND_DISPLAY=wayland-1"})}),"\n"]}),"\n"]})]}),(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsx)(n.li,{children:"Run the following command to push the downloaded model file to the device:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"scp <model filename> ubuntu@<IP addr of the target device>:/etc/models\n"})}),(0,t.jsx)(n.p,{children:"Example"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"unzip rubikpi3_ai_sample_apps_models_labels.zip\ncd rubikpi3_ai_sample_apps_models_labels\nscp yolov8_det_quantized.tflite ubuntu@<IP addr of the target device>:/etc/models/\nscp yolov8.labels ubuntu@<IP addr of the target device>:/etc/labels/\n\nscp inception_v3_quantized.tflite ubuntu@<IP addr of the target device>:/etc/models/\nscp classification.labels ubuntu@<IP addr of the target device>:/etc/labels/\n\nscp hrnet_pose_quantized.tflite ubuntu@<IP addr of the target device>:/etc/models/\nscp hrnet_pose.labels ubuntu@<IP addr of the target device>:/etc/labels/\n\nscp deeplabv3_plus_mobilenet_quantized.tflite ubuntu@<IP addr of the target device>:/etc/models/\nscp deeplabv3_resnet50.labels ubuntu@<IP addr of the target device>:/etc/labels/\n"})}),(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsx)(n.li,{children:"To start the application, run the following command:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-plaintext",children:"gst-ai-parallel-inference\n"})}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["To stop the use case, press ",(0,t.jsx)(n.strong,{children:"Ctrl"})," + ",(0,t.jsx)(n.strong,{children:"C"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"To display the available help options, run the following command:"}),"\n"]}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-plaintext",children:"gst-ai-parallel-inference -h\n"})}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Qualcomm AI Hub often updates models with the latest SDK versions. Using wrong model constants may lead to inaccurate results. If you face such issues, update the model constants. Provide the model constants for the sample application using the following command:"}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'gst-ai-parallel-inference -s /etc/media/video.mp4 \\\n--object-detection-constants="YOLOv8,q-offsets=<21.0, 0.0, 0.0>,q-scales=<3.0546178817749023, 0.003793874057009816, 1.0>;" \\\n--pose-detection-constants="Posenet,q-offsets=<8.0>,q-scales=<0.0040499246679246426>;" \\\n--segmentation-constants="deeplab,q-offsets=<0.0>,q-scales=<1.0>;" \\\n--classification-constants="Inceptionv3,q-offsets=<38.0>,q-scales=<0.17039915919303894>;"\n'})}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.code,{children:"GST_DEBUG"})," environment variable controls the GStreamer debug output. Set the required level to allow logging. For example, to log all warnings, run the following command:"]}),"\n"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c++",children:"export GST_DEBUG=2\n"})}),(0,t.jsx)(n.p,{children:"Known issue"}),(0,t.jsx)(n.p,{children:"In pose detection, the model detects only one person, even if many people are present in the frame."}),(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsx)(n.p,{children:"Image classification using the Inception v3 model trains on the ImageNet data set. As a result, the model can't detect a person because this class isn't included in the data set."})})]})]}),"\n",(0,t.jsx)(n.h2,{id:"more-applications",children:"More applications"}),"\n",(0,t.jsx)(n.p,{children:"The release offers various sample applications. To explore more, see Sample applications."})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},6304:(e,n,s)=>{s.d(n,{A:()=>l});const l=s.p+"assets/images/image-10-64427526a8f13a575a615b6469532ef0.png"},6466:(e,n,s)=>{s.d(n,{A:()=>l});const l=s.p+"assets/images/image-12-5ab4d1eb496646493e4beae225ad1cac.png"},7595:(e,n,s)=>{s.d(n,{A:()=>l});const l=s.p+"assets/images/image-13-66505190f0d758bf07d57b554c94d1d2.png"},7684:(e,n,s)=>{s.d(n,{A:()=>l});const l=s.p+"assets/images/image-14-50c777005979bffdc10712b8d175565c.png"},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>r});var l=s(6540);const t={},i=l.createContext(t);function a(e){const n=l.useContext(i);return l.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),l.createElement(i.Provider,{value:n},e.children)}},9365:(e,n,s)=>{s.d(n,{A:()=>a});s(6540);var l=s(4164);const t={tabItem:"tabItem_Ymn6"};var i=s(4848);function a({children:e,hidden:n,className:s}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,l.A)(t.tabItem,s),hidden:n,children:e})}},9510:(e,n,s)=>{s.d(n,{A:()=>l});const l=s.p+"assets/images/image-16-b70d1422d5298371ad91de4d96d99395.png"}}]);