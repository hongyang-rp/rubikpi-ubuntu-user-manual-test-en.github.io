"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4727],{11470:(e,r,n)=>{n.d(r,{A:()=>y});var a=n(96540),t=n(34164),i=n(23104),s=n(56347),o=n(205),c=n(57485),l=n(31682),d=n(70679);function m(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:r}=e;return!!r&&"object"==typeof r&&"value"in r}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:r,children:n}=e;return(0,a.useMemo)(()=>{const e=r??function(e){return m(e).map(({props:{value:e,label:r,attributes:n,default:a}})=>({value:e,label:r,attributes:n,default:a}))}(n);return function(e){const r=(0,l.XI)(e,(e,r)=>e.value===r.value);if(r.length>0)throw new Error(`Docusaurus error: Duplicate values "${r.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[r,n])}function u({value:e,tabValues:r}){return r.some(r=>r.value===e)}function p({queryString:e=!1,groupId:r}){const n=(0,s.W6)(),t=function({queryString:e=!1,groupId:r}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!r)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return r??null}({queryString:e,groupId:r});return[(0,c.aZ)(t),(0,a.useCallback)(e=>{if(!t)return;const r=new URLSearchParams(n.location.search);r.set(t,e),n.replace({...n.location,search:r.toString()})},[t,n])]}function x(e){const{defaultValue:r,queryString:n=!1,groupId:t}=e,i=h(e),[s,c]=(0,a.useState)(()=>function({defaultValue:e,tabValues:r}){if(0===r.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:r}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${r.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=r.find(e=>e.default)??r[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:r,tabValues:i})),[l,m]=p({queryString:n,groupId:t}),[x,f]=function({groupId:e}){const r=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,t]=(0,d.Dv)(r);return[n,(0,a.useCallback)(e=>{r&&t.set(e)},[r,t])]}({groupId:t}),g=(()=>{const e=l??x;return u({value:e,tabValues:i})?e:null})();(0,o.A)(()=>{g&&c(g)},[g]);return{selectedValue:s,selectValue:(0,a.useCallback)(e=>{if(!u({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);c(e),m(e),f(e)},[m,f,i]),tabValues:i}}var f=n(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=n(74848);function j({className:e,block:r,selectedValue:n,selectValue:a,tabValues:s}){const o=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.a_)(),l=e=>{const r=e.currentTarget,t=o.indexOf(r),i=s[t].value;i!==n&&(c(r),a(i))},d=e=>{let r=null;switch(e.key){case"Enter":l(e);break;case"ArrowRight":{const n=o.indexOf(e.currentTarget)+1;r=o[n]??o[0];break}case"ArrowLeft":{const n=o.indexOf(e.currentTarget)-1;r=o[n]??o[o.length-1];break}}r?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,t.A)("tabs",{"tabs--block":r},e),children:s.map(({value:e,label:r,attributes:a})=>(0,v.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{o.push(e)},onKeyDown:d,onClick:l,...a,className:(0,t.A)("tabs__item",g.tabItem,a?.className,{"tabs__item--active":n===e}),children:r??e},e))})}function w({lazy:e,children:r,selectedValue:n}){const i=(Array.isArray(r)?r:[r]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===n);return e?(0,a.cloneElement)(e,{className:(0,t.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:i.map((e,r)=>(0,a.cloneElement)(e,{key:r,hidden:e.props.value!==n}))})}function b(e){const r=x(e);return(0,v.jsxs)("div",{className:(0,t.A)("tabs-container",g.tabList),children:[(0,v.jsx)(j,{...r,...e}),(0,v.jsx)(w,{...r,...e})]})}function y(e){const r=(0,f.A)();return(0,v.jsx)(b,{...e,children:m(e.children)},String(r))}},19365:(e,r,n)=>{n.d(r,{A:()=>s});n(96540);var a=n(34164);const t={tabItem:"tabItem_Ymn6"};var i=n(74848);function s({children:e,hidden:r,className:n}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,a.A)(t.tabItem,n),hidden:r,children:e})}},28453:(e,r,n)=>{n.d(r,{R:()=>s,x:()=>o});var a=n(96540);const t={},i=a.createContext(t);function s(e){const r=a.useContext(i);return a.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function o(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),a.createElement(i.Provider,{value:r},e.children)}},58275:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>d,contentTitle:()=>l,default:()=>u,frontMatter:()=>c,metadata:()=>a,toc:()=>m});const a=JSON.parse('{"id":"camera-software","title":"Camera Software","description":"Overview","source":"@site/docs/7.camera-software.md","sourceDirName":".","slug":"/camera-software","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/camera-software","draft":false,"unlisted":false,"editUrl":"https://github.com/hongyang-rp/rubikpi-ubuntu-user-manual-test-en.github.io/tree/main/docs/7.camera-software.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Robot Development","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/robot-development"},"next":{"title":"IoT Connectivity","permalink":"/rubikpi-ubuntu-user-manual-test-en.github.io/docs/iot-connectivity"}}');var t=n(74848),i=n(28453),s=n(11470),o=n(19365);const c={},l="Camera Software",d={},m=[{value:"Overview",id:"overview",level:2},{value:"Stream cameras",id:"stream-cameras",level:2},{value:"Start a single camera stream",id:"start-a-single-camera-stream",level:3},{value:"Encode video",id:"encode-video",level:3},{value:"Encode video and take photos",id:"encode-video-and-take-photos",level:3},{value:"Preview the camera content",id:"preview-the-camera-content",level:3},{value:"Display three 720p YUV video streams",id:"display-three-720p-yuv-video-streams",level:3},{value:"Camera stream with socket",id:"camera-stream-with-socket",level:3},{value:"4K AVC and a 480p AVC streams from live source",id:"4k-avc-and-a-480p-avc-streams-from-live-source",level:3},{value:"Three 1080p AVC data streams from live source",id:"three-1080p-avc-data-streams-from-live-source",level:3},{value:"Multi-camera display",id:"multi-camera-display",level:2},{value:"Two 720p streams - one from each camera, displayed side-by-side",id:"two-720p-streams---one-from-each-camera-displayed-side-by-side",level:3},{value:"Two 720p streams - one from each camera, displayed picture-in-picture",id:"two-720p-streams---one-from-each-camera-displayed-picture-in-picture",level:3},{value:"Transform and transcode",id:"transform-and-transcode",level:2},{value:"Rotation",id:"rotation",level:3},{value:"Horizontal flip",id:"horizontal-flip",level:3},{value:"Vertical flip",id:"vertical-flip",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2}];function h(e){const r={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.header,{children:(0,t.jsx)(r.h1,{id:"camera-software",children:"Camera Software"})}),"\n",(0,t.jsx)(r.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(r.p,{children:"This section introduces the camera subsystem that receives data through the MIPI CSI interface."}),"\n",(0,t.jsx)(r.p,{children:"USB camera data is transmitted through the USB interface, which will not be discussed in this chapter. Refer to the USB chapter to learn about the use of USB cameras."}),"\n",(0,t.jsxs)(r.p,{children:["Network camera data is transmitted through the network interface, which is also not involved in the camera subsystem. Devices can receive network camera data through the GStreamer ",(0,t.jsx)(r.a,{href:"https://gstreamer.freedesktop.org/documentation/rtsp/rtspsrc.html?gi-language=c",children:"rtspsrc"})," plugin."]}),"\n",(0,t.jsx)(r.p,{children:"The following figure shows the components of the Qualcomm camera."}),"\n",(0,t.jsx)(r.p,{children:"![](Document\\ Home/images/image-camera-1.jpg)"}),"\n",(0,t.jsx)(r.p,{children:"The following components are provided by Qualcomm:"}),"\n",(0,t.jsxs)(r.table,{children:[(0,t.jsx)(r.thead,{children:(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.th,{children:"Component"}),(0,t.jsx)(r.th,{children:"Description"})]})}),(0,t.jsxs)(r.tbody,{children:[(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"GST camera plugin (qtiqmmfsrc)"}),(0,t.jsx)(r.td,{children:"GStreamer plugin for Qualcomm's camera subsystem"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"Camera core software"}),(0,t.jsx)(r.td,{children:"Qualcomm's proprietary camera software, providing interfaces for developing camera sensor drivers, camera tuning, and custom software nodes"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"Camera core driver"}),(0,t.jsx)(r.td,{children:"Qualcomm camera subsystem driver in the downstream Linux kernel"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:"CamSS V4L2 driver"}),(0,t.jsx)(r.td,{children:"Qualcomm camera subsystem driver in the upstream Linux kernel"})]})]})]}),"\n",(0,t.jsx)(r.h2,{id:"stream-cameras",children:"Stream cameras"}),"\n",(0,t.jsx)(r.p,{children:"Qualcomm provides a GStreamer plugin that allows application developers to interact with the Qualcomm camera subsystem."}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Prerequisite"})}),"\n",(0,t.jsx)(r.p,{children:"Enable the display:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"sudo -i\r\nsystemctl stop gdm\r\nsudo dpkg-reconfigure weston-autostart\r\nexport XDG_RUNTIME_DIR=/run/user/$(id -u ubuntu)\n"})}),"\n",(0,t.jsx)(r.h3,{id:"start-a-single-camera-stream",children:"Start a single camera stream"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Run the following command in the device terminal to start the camera with 720p at 30 FPS configuration. The frames from the camera sensor are discarded by the fakesink."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:" gst-launch-1.0 -e qtiqmmfsrc name=camsrc camera=0 ! 'video/x-raw,format=NV12,\\\r\n width=1280,height=720,framerate=30/1' ! fakesink\n"})}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:'If the gst pipeline status changes to "PLAYING" as shown below, it indicates that the camera is running. Since this command dumps the camera frames to fakesink, no content will be saved on the device.'}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"Setting pipeline to PAUSED ...\r\nPipeline is live and does not need PREROLL ...\r\nSetting pipeline to PLAYING ...\r\nNew clock: GstSystemClock\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.h3,{id:"encode-video",children:"Encode video"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Run the following command in the device terminal to start the camera with 720p at 30 FPS configuration and save the video stream as a video file after H.264 video encoding."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:'gst-launch-1.0 -e qtiqmmfsrc name=camsrc camera=0 ! \\\r\nvideo/x-raw,format=NV12,width=1280,height=720,framerate=30/1,\\\r\ninterlace-mode=progressive,colorimetry=bt601 ! v4l2h264enc \\\r\ncapture-io-mode=4 output-io-mode=5 extra-controls="controls,video_bitrate=6000000,\\\r\nvideo_bitrate_mode=0;" ! h264parse ! mp4mux ! filesink location=/opt/mux_avc.mp4\n'})}),"\n",(0,t.jsx)(r.p,{children:'If the gst pipeline status changes to "PLAYING", it indicates that the camera is running.'}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.em,{children:"/opt/mux_avc.mp4"})," is generated on the device. Copy the recorded content from the device by running the following scp command on the host PC:"]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"$ scp -r root@[ip-addr]:/opt/mux_avc.mp4 .\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.h3,{id:"encode-video-and-take-photos",children:"Encode video and take photos"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Run the following command in the device terminal:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:'gst-pipeline-app -e qtiqmmfsrc name=camsrc camera=0 ! \\\r\nvideo/x-raw,format=NV12,width=1280,height=720,framerate=30/1,\\\r\ninterlace-mode=progressive,colorimetry=bt601 ! v4l2h264enc \\\r\ncapture-io-mode=4 output-io-mode=5 extra-controls="controls,video_bitrate=6000000,\\\r\nvideo_bitrate_mode=0;" ! h264parse ! mp4mux ! filesink location=/opt/mux_avc.mp4 \\\r\ncamsrc.image_1 ! "image/jpeg,width=1280,height=720,framerate=30/1" \\\r\n! multifilesink location=/opt/frame%d.jpg async=false sync=true enable-last-sample=false\n'})}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:["Press ",(0,t.jsx)(r.strong,{children:"Enter"}),". This command will print the following menu and wait for user input."]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"##################################### MENU #####################################\r\n\r\n============================== Pipeline Controls==============================\r\n(0) NULL: Set the pipeline into NULL state\r\n(1) READY: Set the pipeline into READY state\r\n(2) PAUSED: Set the pipeline into PAUSED state\r\n(3) PLAYING: Set the pipeline into PLAYING state\r\n\r\n==================================== Other====================================\r\n(p) Plugin Mode: Choose a plugin which to control\r\n(q) Quit : Exit the application\r\n\r\nChoose an option:\r\n\n"})}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Use the following menu steps to take a photo while recording the video."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"(1) ready -> (3) Playing -> (p)Plugin Mode : Select (8)camerasrc -> (37) capture-image -> (1): still - Snapshot ->(1) Snapshot count ( 'guint' value for arg1)\n"})}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:["To stop the camera, press ",(0,t.jsx)(r.strong,{children:"Enter"}),", then press ",(0,t.jsx)(r.strong,{children:"B"})," to go back and press ",(0,t.jsx)(r.strong,{children:"q"})," to exit. The recorded video file and captured Document\\ Home/images are saved in the ",(0,t.jsx)(r.em,{children:"/opt/"})," directory. Copy the recorded content from the device by running the following scp command on the host PC:"]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"$ scp -r root@[ip-addr]:/opt/<file name> .\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.h3,{id:"preview-the-camera-content",children:"Preview the camera content"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"gst-launch-1.0 -e qtiqmmfsrc name=camsrc video_1::type=preview ! video/x-raw,format=NV12,width=1920,height=1080,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! waylandsink fullscreen=true sync=false\n"})}),"\n",(0,t.jsx)(r.p,{children:"This pipeline shows a single 1080p stream captured from the camera and sent to the display."}),"\n",(0,t.jsx)(r.p,{children:"![](Document\\ Home/images/image-camera-2.jpg)"}),"\n",(0,t.jsx)(r.h3,{id:"display-three-720p-yuv-video-streams",children:"Display three 720p YUV video streams"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-bash",children:'gst-launch-1.0 -e qtivcomposer name=mixer sink_0::position="<0, 0>" sink_0::dimensions="<480, 270>" sink_1::position="<480, 0>" sink_1::dimensions="<480, 270>" sink_2::position="<960, 0>" sink_2::dimensions="<480, 270>" mixer. ! queue ! waylandsink fullscreen=true qtiqmmfsrc name=camsrc camera=0 video_0::type=preview video_1::type=video ! video/x-raw,format=NV12_Q08C,width=1280,height=720,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! queue ! mixer. camsrc. ! video/x-raw,format=NV12,width=1280,height=720,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! queue ! mixer. camsrc. ! video/x-raw,format=NV12,width=1280,height=720,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! queue ! mixer.\n'})}),"\n",(0,t.jsx)(r.p,{children:"This pipeline shows three 720p streams captured from the camera and sent to the display, with each stream being displayed in a different position on the screen."}),"\n",(0,t.jsx)(r.p,{children:"![](Document\\ Home/images/image-camera-3.jpg)"}),"\n",(0,t.jsx)(r.h3,{id:"camera-stream-with-socket",children:"Camera stream with socket"}),"\n",(0,t.jsx)(r.p,{children:"This use case demonstrates how to store the camera stream in a socket, encode the camera stream into AVC format, and store it in a file."}),"\n",(0,t.jsx)(r.p,{children:"In console 1:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"gst-launch-1.0 -e qtisocketsrc socket=/tmp/input.sock ! video/x-raw,format=NV12,width=1920,height=1080,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! v4l2h264enc capture-io-mode=4 output-io-mode=5 ! h264parse ! mp4mux ! queue ! filesink location=/opt/video.mp4\n"})}),"\n",(0,t.jsx)(r.p,{children:"In console 2:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"gst-launch-1.0 -e qtiqmmfsrc name=camsrc ! video/x-raw,format=NV12,width=1920,height=1080,framerate=30/1 ! qtisocketsink socket=/tmp/input.sock\n"})}),"\n",(0,t.jsx)(r.p,{children:"The following figure shows the execution flow of the pipeline:"}),"\n",(0,t.jsx)(r.p,{children:"![](Document\\ Home/images/image-camera-4.jpg)"}),"\n",(0,t.jsx)(r.h3,{id:"4k-avc-and-a-480p-avc-streams-from-live-source",children:"4K AVC and a 480p AVC streams from live source"}),"\n",(0,t.jsx)(r.p,{children:"The following pipeline encodes a 4K stream and a 1080p stream from a camera source. Each encoded data stream is multiplexed into different files."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-c++",children:'gst-launch-1.0 -e qtiqmmfsrc name=camsrc video_0::type=preview ! video/x-raw,format=NV12_Q08C,width=3840,height=2160,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! queue ! v4l2h264enc capture-io-mode=4 output-io-mode=5 ! queue ! h264parse ! mp4mux ! queue ! filesink location="/opt/mux1.mp4" camsrc. ! video/x-raw,format=NV12_Q08C,width=640,height=480,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! queue ! v4l2h264enc capture-io-mode=4 output-io-mode=5 ! queue ! h264parse ! mp4mux ! queue ! filesink location="/opt/mux2.mp4"\n'})}),"\n",(0,t.jsx)(r.p,{children:"The following figure shows the execution flow of the pipeline:"}),"\n",(0,t.jsx)(r.p,{children:"![](Document\\ Home/images/image-camera-5.jpg)"}),"\n",(0,t.jsx)(r.h3,{id:"three-1080p-avc-data-streams-from-live-source",children:"Three 1080p AVC data streams from live source"}),"\n",(0,t.jsx)(r.p,{children:"The following pipeline encodes three 1080p streams from a camera source. Each encoded data stream is multiplexed into different files."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-c++",children:'gst-launch-1.0 -e qtiqmmfsrc name=camsrc video_0::type=preview ! video/x-raw,format=NV12_Q08C,width=1920,height=1080,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! queue ! v4l2h264enc capture-io-mode=4 output-io-mode=5 ! queue ! h264parse ! mp4mux ! queue ! filesink location="/opt/mux1.mp4" camsrc. ! video/x-raw,format=NV12_Q08C,width=1920,height=1080,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! queue ! v4l2h264enc capture-io-mode=4 output-io-mode=5 ! queue ! h264parse ! mp4mux ! queue ! filesink location="/opt/mux2.mp4" camsrc. ! video/x-raw,format=NV12_Q08C,width=1920,height=1080,framerate=30/1,interlace-mode=progressive,colorimetry=bt601 ! queue ! v4l2h264enc capture-io-mode=4 output-io-mode=5 ! queue ! h264parse ! mp4mux ! queue ! filesink location="/opt/mux3.mp4"\n'})}),"\n",(0,t.jsx)(r.p,{children:"The following figure shows the execution flow of the pipeline:"}),"\n",(0,t.jsx)(r.p,{children:"![](Document\\ Home/images/image-camera-6.jpg)"}),"\n",(0,t.jsx)(r.h2,{id:"multi-camera-display",children:"Multi-camera display"}),"\n",(0,t.jsx)(r.p,{children:"The multi-camera/multi-client use cases demonstrate scenarios where multiple camera video streams are displayed in various layouts such as picture-in-picture (PiP) or side-by-side."}),"\n",(0,t.jsxs)(s.A,{children:[(0,t.jsxs)(o.A,{value:"side",label:"Side-by-side",children:[(0,t.jsx)(r.h3,{id:"two-720p-streams---one-from-each-camera-displayed-side-by-side",children:"Two 720p streams - one from each camera, displayed side-by-side"}),(0,t.jsx)(r.p,{children:"The pipeline demonstrates the display of two 720p video streams, one from the main camera and one from the auxiliary camera, arranged in a side-by-side layout."}),(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-bash",children:'gst-launch-1.0 -e qtivcomposer name=mixer sink_0::position="<0, 0>" sink_0::dimensions="<640, 360>" sink_1::position="<640, 0>" sink_1::dimensions="<640, 360>" mixer. ! queue ! waylandsink enable-last-sample=false fullscreen=true qtiqmmfsrc name=camsrc_0 camera=0 ! video/x-raw, format=NV12, width=1280, height=720, framerate=30/1 ! mixer. qtiqmmfsrc name=camsrc_1 camera=1 ! video/x-raw, format=NV12, width=1280, height=720, framerate=30/1 ! mixer.\r\n\n'})}),(0,t.jsx)(r.p,{children:"The following figure shows the execution flow of the pipeline:"}),(0,t.jsx)(r.p,{children:"![](Document\\ Home/images/image-camera-7.jpg)"})]}),(0,t.jsxs)(o.A,{value:"Picture",label:"Picture-in-picture",children:[(0,t.jsx)(r.h3,{id:"two-720p-streams---one-from-each-camera-displayed-picture-in-picture",children:"Two 720p streams - one from each camera, displayed picture-in-picture"}),(0,t.jsx)(r.p,{children:"The pipeline demonstrates the display of two 720p video streams, one from the main camera and one from the auxiliary camera, arranged in a picture-in-picture layout."}),(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-bash",children:'gst-launch-1.0 -e qtivcomposer name=mixer sink_0::position="<0, 0>" sink_0::dimensions="<1280, 720>" sink_1::position="<590, 310>" sink_1::dimensions="<640, 360>" mixer. ! queue ! waylandsink enable-last-sample=false fullscreen=true qtiqmmfsrc name=camsrc_0 camera=0 ! video/x-raw, format=NV12, width=1280, height=720, framerate=30/1 ! mixer. qtiqmmfsrc name=camsrc_1 camera=1 ! video/x-raw, format=NV12, width=1280, height=720, framerate=30/1 ! mixer.\r\n\n'})})]})]}),"\n",(0,t.jsx)(r.h2,{id:"transform-and-transcode",children:"Transform and transcode"}),"\n",(0,t.jsx)(r.p,{children:"The following use case demonstrate the process of adjusting the scene in a camera."}),"\n",(0,t.jsx)(r.h3,{id:"rotation",children:"Rotation"}),"\n",(0,t.jsx)(r.p,{children:"This use case demonstrates rotating the scene from the camera by 180 degrees. The rotated image is displayed on a local display."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-bash",children:"gst-launch-1.0 -e qtiqmmfsrc name=camsrc video_0::type=video video_1::type=preview ! video/x-raw,format=NV12,width=1920,height=1080,framerate=30/1 ! qtivtransform engine=gles rotate=180 ! waylandsink fullscreen=true async=false sync=false\n"})}),"\n",(0,t.jsx)(r.p,{children:"The following figure shows the execution flow of the pipeline:"}),"\n",(0,t.jsx)(r.p,{children:"![](Document\\ Home/images/image-camera-8.jpg)"}),"\n",(0,t.jsx)(r.admonition,{type:"tip",children:(0,t.jsx)(r.p,{children:"Currently, only 180-degree rotation is supported."})}),"\n",(0,t.jsx)(r.h3,{id:"horizontal-flip",children:"Horizontal flip"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-typescript",children:"gst-launch-1.0 -e qtiqmmfsrc name=camsrc video_0::type=video video_1::type=preview ! video/x-raw,format=NV12,width=1920,height=1080,framerate=30/1 ! qtivtransform engine=gles flip-horizontal=true ! waylandsink fullscreen=true\n"})}),"\n",(0,t.jsx)(r.h3,{id:"vertical-flip",children:"Vertical flip"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-plain text",children:"gst-launch-1.0 -e qtiqmmfsrc name=camsrc video_0::type=video video_1::type=preview ! video/x-raw,format=NV12,width=1920,height=1080,framerate=30/1 ! qtivtransform engine=gles flip-vertical=true ! waylandsink fullscreen=true\n"})}),"\n",(0,t.jsx)(r.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsx)(r.p,{children:"If the camera is unable to display or capture images, check the following:"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Check the camera module connection based on [Connect the camera cable](Document\\ Home/2.peripherals-and-interfaces/3.csi.md#cameracable)"}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Check the sensor probe."}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Run the following command to collect logs."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-shell",children:"journalctl -f > /opt/log.txt\n"})}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:'Search the logs for "probe success". "Probe success" indicates that the camera module has been powered on and is responding to I2C control. If a specific sensor does not have the "probe success" log, the issue may lie in the flexible cable connection or the camera module hardware.'}),"\n",(0,t.jsx)(r.p,{children:"The following log indicates that an IMX477 has been detected:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-shell",children:"[   80.645992] CAM_INFO: CAM-SENSOR: cam_sensor_driver_cmd: 939: Probe success,slot:7,slave_addr:0x34,sensor_id:0x477, is always on: 0\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Check the camera sensor driver command."}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:["Collect the logs using the ",(0,t.jsx)(r.code,{children:"journalctl -f > /opt/log.txt"})," command."]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:'Search for "cam_sensor_driver_cmd".'}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:'"CAM_START_DEV Success" indicates that the camera sensor streaming has started.'}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:'"CAM_STOP_DEV Success" indicates that the camera sensor streaming has stopped.'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"For example:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-shell",children:"start:\r\n[   81.172814] CAM_INFO: CAM-SENSOR: cam_sensor_driver_cmd: 1129: CAM_START_DEV Success, sensor_id:0x477,sensor_slave_addr:0x34\r\nstop:\r\n[   88.905241] CAM_INFO: CAM-SENSOR: cam_sensor_driver_cmd: 1157: CAM_STOP_DEV Success, sensor_id:0x477,sensor_slave_addr:0x34\n"})}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Check the sensor streaming."}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"Enable CSID SOF/EOF IRQ logging, then execute the camera streaming command."}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-shell",children:"mount -o rw,remount /usr\r\nmount -t debugfs none /sys/kernel/debug/\r\necho 0x8 > /sys/module/camera/parameters/debug_mdl\r\necho 3 >/sys/kernel/debug/camera_ife/ife_csid_debug\r\necho 1 > /sys/kernel/tracing/tracing_on\r\necho 1 > /sys/kernel/tracing/events/camera/cam_log_debug/enable\r\necho 2 > /sys/module/camera/parameters/debug_type\r\ncat /sys/kernel/tracing/trace_pipe > trace.txt\n"})}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:['The captured logs can provide detailed information about the SOF and EOF. Search for "irq_status_ipp" in the log file ',(0,t.jsx)(r.em,{children:"trace.txt"}),"."]}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"BIT12(0x1000) indicates the SOF data packet."}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsx)(r.p,{children:"BIT9(0x200) indicates the EOF data packet."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"The logs are as follows:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-shell",children:"<idle>-0       [000] d.h1. 19287.546764: cam_log_debug:\r\nCAM_DBG: CAM-ISP: cam_ife_csid_irq: 4996: irq_status_ipp = 0x1110 cam-server-25604     [000] dNH.. 19287.561705: cam_log_debug:\r\nCAM_DBG: CAM-ISP: cam_ife_csid_irq: 4996: irq_status_ipp = 0xee8\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function u(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}}}]);